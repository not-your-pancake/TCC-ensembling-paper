{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0271e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_bandarban = pd.read_csv('../../1980-2024-dataset/bandarban_historical_weather_1980_2024.csv')\n",
    "df_bandarban = df_bandarban.drop('district', axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0929e80",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "921cf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = df_bandarban.copy()\n",
    "if 'date' not in df.columns:\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "\n",
    "# 'dew_point', 'atmospheric_pressure','max_temperature(degree C)' [collected based on the corrilation matrix]\n",
    "\n",
    "# adding lagging for 3 days\n",
    "lags = [1, 2, 3]\n",
    "lag_cols = []\n",
    "\n",
    "for lag in lags:\n",
    "    df[f'dew_lag_{lag}'] = df['dew_point'].shift(lag)\n",
    "    df[f'atm_lag_{lag}'] = df['atmospheric_pressure'].shift(lag)\n",
    "    df[f'feels_lag_{lag}'] = df['max_temperature(degree C)'].shift(lag)\n",
    "\n",
    "    lag_cols.extend([f'dew_lag_{lag}', f'atm_lag_{lag}', f'feels_lag_{lag}'])\n",
    "\n",
    "# 7-day Rolling Average\n",
    "df['dew_roll_7'] = df['dew_point'].transform(lambda x: x.rolling(window=7).mean())\n",
    "df['atm_roll_7'] = df['atmospheric_pressure'].transform(lambda x: x.rolling(window=7).mean())\n",
    "df['feels_roll_7'] = df['max_temperature(degree C)'].transform(lambda x: x.rolling(window =7).mean())\n",
    "\n",
    "\n",
    "rolling_cols = ['dew_roll_7', 'atm_roll_7', 'feels_roll_7']\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "def add_fourier_features(df,col,period,n_terms=10):\n",
    "    for n in range(1, n_terms + 1):\n",
    "        df[f'{col}_sin_{n}'] = np.sin(2 * np.pi * n * df.index / period)\n",
    "        df[f'{col}_cos_{n}'] = np.cos(2 * np.pi * n * df.index / period)\n",
    "    return df\n",
    "\n",
    "df = add_fourier_features(df, 'day_of_year', period=365, n_terms=3)\n",
    "fourier_cols = [c for c in df.columns if c.startswith('day_of_year_sin') or c.startswith('day_of_year_cos')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES = [\n",
    "\n",
    "\n",
    "#     ]\n",
    "\n",
    "FEATURES = [ 'dew_point', 'atmospheric_pressure'] + fourier_cols # + lag_cols + rolling_cols # (first e eita uncomment kore feature importance dekhben. then 0.02 minmum importance gula note down kore prediction korben)\n",
    "# 97.72/98.07 *-0.34\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df['temperature(degree C)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58458f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.4531 - val_loss: 0.1298\n",
      "Epoch 2/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1418 - val_loss: 0.1210\n",
      "Epoch 3/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1267 - val_loss: 0.1091\n",
      "Epoch 4/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1230 - val_loss: 0.1099\n",
      "Epoch 5/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1166 - val_loss: 0.1055\n",
      "Epoch 6/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1112 - val_loss: 0.1038\n",
      "Epoch 7/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1072 - val_loss: 0.1064\n",
      "Epoch 8/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1075 - val_loss: 0.1028\n",
      "Epoch 9/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1056 - val_loss: 0.1011\n",
      "Epoch 10/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1037 - val_loss: 0.1065\n",
      "Epoch 11/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1049 - val_loss: 0.1044\n",
      "Epoch 12/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1034 - val_loss: 0.1052\n",
      "Epoch 13/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1004 - val_loss: 0.1059\n",
      "Epoch 14/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1001 - val_loss: 0.1014\n",
      "Epoch 15/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0991 - val_loss: 0.1060\n",
      "Epoch 16/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1034 - val_loss: 0.1069\n",
      "Epoch 17/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1002 - val_loss: 0.1035\n",
      "Epoch 18/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1006 - val_loss: 0.1066\n",
      "Epoch 19/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0970 - val_loss: 0.1054\n",
      "Epoch 20/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0984 - val_loss: 0.1044\n",
      "Epoch 21/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0965 - val_loss: 0.1019\n",
      "Epoch 22/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0966 - val_loss: 0.1030\n",
      "Epoch 23/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0951 - val_loss: 0.1046\n",
      "Epoch 24/100\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0958 - val_loss: 0.1105\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "GRU Results for temperature :\n",
      "Mean Squared Error: 1.7419\n",
      "RMSE: 1.3198\n",
      "R² Score: 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "\n",
      "Average RMSE from CV: 1.1783\n",
      "Average R² from CV: 0.8843\n",
      "Average MSE: 1.3962\n",
      "Individual Fold RMSEs: [np.float64(1.233016720645276), np.float64(1.077586824255452), np.float64(1.1697958496604595), np.float64(1.096276699263201), np.float64(1.314979486571461)]\n",
      "\n",
      " R2 ~ -2.5419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "    # Create an instance with specific parameters\n",
    "early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=15,          # Wait 15 epochs for improvement before stopping\n",
    "        restore_best_weights=True  # Very important: keeps the best version of your model\n",
    "    )\n",
    "\n",
    "    # 1. Scale the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "    # 2. Reshape for GRU: (samples, time_steps, features)\n",
    "    # Here we use time_steps=1. If you want sequences, you'd need a sliding window function.\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "    # Split data (matching your non-shuffle 80/20 split)\n",
    "split_idx = int(len(X_reshaped) * 0.8)\n",
    "X_train, X_test = X_reshaped[:split_idx], X_reshaped[split_idx:]\n",
    "y_train, y_test = y_scaled[:split_idx], y_scaled[split_idx:]\n",
    "\n",
    "\n",
    "def build_gru(input_shape):\n",
    "        model = Sequential([\n",
    "            GRU(64, activation='tanh', input_shape=input_shape, return_sequences=False, recurrent_dropout=0.1),\n",
    "            Dropout(0.2),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1) # Output layer for regression\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        return model\n",
    "\n",
    "    # Train initial model\n",
    "gru_model = build_gru((X_train.shape[1], X_train.shape[2]))\n",
    "gru_model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=100, \n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping], \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predict and Inverse Scale\n",
    "y_pred_scaled = gru_model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "mse_gru = mean_squared_error(y_test_unscaled, y_pred)\n",
    "rmse_gru = np.sqrt(mse_gru)\n",
    "r2_gru = r2_score(y_test_unscaled, y_pred)\n",
    "\n",
    "print(f\"\\nGRU Results for temperature :\")\n",
    "print(f'Mean Squared Error: {mse_gru:.4f}')\n",
    "print(f'RMSE: {rmse_gru:.4f}')\n",
    "print(f'R² Score: {r2_gru:.4f}')\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rmse_list_gru = []\n",
    "r2_list_gru = []\n",
    "mse_list_gru = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_reshaped):\n",
    "        X_train_kf, X_test_kf = X_reshaped[train_index], X_reshaped[test_index]\n",
    "        y_train_kf, y_test_kf = y_scaled[train_index], y_scaled[test_index]\n",
    "\n",
    "        # Rebuild/Reset model for each fold\n",
    "        gru_kf = build_gru((X_train_kf.shape[1], X_train_kf.shape[2]))\n",
    "        gru_kf.fit(X_train_kf, y_train_kf, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "        # Predict and Inverse\n",
    "        y_pred_kf_scaled = gru_kf.predict(X_test_kf)\n",
    "        y_pred_kf = scaler_y.inverse_transform(y_pred_kf_scaled)\n",
    "        y_test_kf_unscaled = scaler_y.inverse_transform(y_test_kf)\n",
    "\n",
    "        mse_kf = mean_squared_error(y_test_kf_unscaled, y_pred_kf)\n",
    "        rmse_list_gru.append(np.sqrt(mse_kf))\n",
    "        mse_list_gru.append(mse_kf)\n",
    "        r2_list_gru.append(r2_score(y_test_kf_unscaled, y_pred_kf))\n",
    "\n",
    "average_r2_gru = np.mean(r2_list_gru)\n",
    "average_mse_gru = np.mean(mse_list_gru)\n",
    "average_rmse_gru = np.mean(rmse_list_gru)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Average RMSE from CV: {average_rmse_gru:.4f}\")\n",
    "print(f\"Average R² from CV: {average_r2_gru:.4f}\")\n",
    "print(f\"Average MSE: {average_mse_gru:.4f}\")\n",
    "print(f\"Individual Fold RMSEs: {rmse_list_gru}\")\n",
    "\n",
    "diff = (r2_gru - np.mean(r2_list_gru))*100\n",
    "print ( f'\\n R2 ~ {diff:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a5925d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRU Permutation Feature Importances:\n",
      "                Feature  Importance\n",
      "0             dew_point    9.641436\n",
      "4     day_of_year_sin_2    0.676416\n",
      "5     day_of_year_cos_2    0.659937\n",
      "3     day_of_year_cos_1    0.615340\n",
      "6     day_of_year_sin_3    0.433408\n",
      "7     day_of_year_cos_3    0.270914\n",
      "1  atmospheric_pressure    0.161488\n",
      "2     day_of_year_sin_1    0.036409\n"
     ]
    }
   ],
   "source": [
    "# Permutation Importance Implementation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_permutation_importance(model, X_val, y_val, scaler_y, feature_names):\n",
    "    \"\"\"\n",
    "    Calculates importance by measuring how much the MSE increases \n",
    "    when a single feature is randomly shuffled.\n",
    "    \"\"\"\n",
    "    # Baseline prediction\n",
    "    baseline_preds = model.predict(X_val, verbose=0)\n",
    "    baseline_mse = mean_squared_error(scaler_y.inverse_transform(y_val), \n",
    "                                     scaler_y.inverse_transform(baseline_preds))\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for i in range(X_val.shape[2]):  # Iterate through each feature\n",
    "        save = X_val[:, :, i].copy()\n",
    "        \n",
    "        # Shuffle the current feature across all samples\n",
    "        np.random.shuffle(X_val[:, :, i])\n",
    "        \n",
    "        # Predict with shuffled feature\n",
    "        shuffled_preds = model.predict(X_val, verbose=0)\n",
    "        shuffled_mse = mean_squared_error(scaler_y.inverse_transform(y_val), \n",
    "                                         scaler_y.inverse_transform(shuffled_preds))\n",
    "        \n",
    "        # Importance is the increase in error\n",
    "        importances.append(max(0, shuffled_mse - baseline_mse))\n",
    "        \n",
    "        # Restore the original feature values\n",
    "        X_val[:, :, i] = save\n",
    "\n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    return importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# --- Execute ---\n",
    "# Note: Use your X_test and y_test from the previous step\n",
    "feature_importance_gru = calculate_permutation_importance(\n",
    "    gru_model, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    scaler_y, \n",
    "    FEATURES\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nGRU Permutation Feature Importances:\")\n",
    "print(feature_importance_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56352f",
   "metadata": {},
   "source": [
    "## predicitng temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f9767e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dew_point', 'atmospheric_pressure'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m FEATURES = [ \u001b[33m'\u001b[39m\u001b[33mdew_point\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33matmospheric_pressure\u001b[39m\u001b[33m'\u001b[39m] + fourier_cols\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Prepare features for prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m future_X = \u001b[43mfuture_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Scale features\u001b[39;00m\n\u001b[32m     28\u001b[39m future_X_scaled = scaler_X.transform(future_X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['dew_point', 'atmospheric_pressure'] not in index\""
     ]
    }
   ],
   "source": [
    "# generate a dataframe for predicted tempeature for 2025 and 2026 \n",
    "future_dates = pd.date_range(start='2025-01-01', end='2026-12-31', freq='D')\n",
    "\n",
    "future_df = pd.DataFrame({'date': future_dates})\n",
    "\n",
    "future_df['year'] = future_df['date'].dt.year\n",
    "future_df['month'] = future_df['date'].dt.month\n",
    "future_df['day'] = future_df['date'].dt.day\n",
    "future_df['day_of_year'] = future_df['date'].dt.dayofyear\n",
    "\n",
    "future_df = add_fourier_features(future_df, 'day_of_year', period=365, n_terms=3)\n",
    "# For simplicity, we'll fill lag and rolling features with the mean of the training data\n",
    "\n",
    "for lag in lags:\n",
    "    future_df[f'dew_lag_{lag}'] = df[f'dew_lag_{lag}'].mean()\n",
    "    future_df[f'atm_lag_{lag}'] = df[f'atm_lag_{lag}'].mean()\n",
    "    future_df[f'feels_lag_{lag}'] = df[f'feels_lag_{lag}'].mean()\n",
    "\n",
    "\n",
    "future_df['dew_roll_7'] = df['dew_roll_7'].mean()\n",
    "future_df['atm_roll_7'] = df['atm_roll_7'].mean()\n",
    "future_df['feels_roll_7'] = df['feels_roll_7'].mean()\n",
    "\n",
    "FEATURES = [ 'dew_point', 'atmospheric_pressure'] + fourier_cols\n",
    "# Prepare features for prediction\n",
    "future_X = future_df[FEATURES]\n",
    "# Scale features\n",
    "future_X_scaled = scaler_X.transform(future_X)\n",
    "# Reshape for GRU\n",
    "future_X_reshaped = future_X_scaled.reshape((future_X_scaled.shape[0], 1, future_X_scaled.shape[1]))\n",
    "# Predict future temperatures\n",
    "future_preds_scaled = gru_model.predict(future_X_reshaped, verbose=0)\n",
    "future_preds = scaler_y.inverse_transform(future_preds_scaled)\n",
    "future_df['predicted_temperature'] = future_preds\n",
    "\n",
    "print(\"\\nPredicted Temperatures for 2025-2026:\")\n",
    "print(future_df[['date', 'predicted_temperature']])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7f5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>predicted_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>21.335312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>21.490690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>20.723204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>20.578735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>20.703154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  predicted_temperature\n",
       "4033 2024-12-27              21.335312\n",
       "4034 2024-12-28              21.490690\n",
       "4035 2024-12-29              20.723204\n",
       "4036 2024-12-30              20.578735\n",
       "4037 2024-12-31              20.703154"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For 2026, repeat the same process (assuming you have a 2026 dataframe)\n",
    "\n",
    "# Prepare 2026 data\n",
    "df_2026 = df_bandarban.copy()\n",
    "if 'date' not in df_2026.columns:\n",
    "    df_2026['date'] = pd.to_datetime(df_2026[['year', 'month', 'day']])\n",
    "\n",
    "# Apply lag and rolling features (same as training)\n",
    "for lag in [1, 2, 3]:\n",
    "    df_2026[f'dew_lag_{lag}'] = df_2026['dew_point'].shift(lag)\n",
    "    df_2026[f'atm_lag_{lag}'] = df_2026['atmospheric_pressure'].shift(lag)\n",
    "    df_2026[f'feels_lag_{lag}'] = df_2026['max_temperature(degree C)'].shift(lag)\n",
    "\n",
    "df_2026['dew_roll_7'] = df_2026['dew_point'].transform(lambda x: x.rolling(window=7).mean())\n",
    "df_2026['atm_roll_7'] = df_2026['atmospheric_pressure'].transform(lambda x: x.rolling(window=7).mean())\n",
    "df_2026['feels_roll_7'] = df_2026['max_temperature(degree C)'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "df_2026['day_of_year'] = df_2026['date'].dt.dayofyear\n",
    "df_2026 = add_fourier_features(df_2026, 'day_of_year', period=365, n_terms=3)\n",
    "\n",
    "df_2026 = df_2026.dropna().reset_index(drop=True)\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_2026 = df_2026[FEATURES]\n",
    "X_2026_scaled = scaler_X.transform(X_2026)\n",
    "X_2026_reshaped = X_2026_scaled.reshape((X_2026_scaled.shape[0], 1, X_2026_scaled.shape[1]))\n",
    "\n",
    "# Predict\n",
    "y_2026_pred_scaled = gru_model.predict(X_2026_reshaped)\n",
    "y_2026_pred = scaler_y.inverse_transform(y_2026_pred_scaled)\n",
    "\n",
    "df_pred_2026 = df_2026[['date']].copy()\n",
    "df_pred_2026['predicted_temperature'] = y_2026_pred.flatten()\n",
    "\n",
    "df_pred_2026.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332e411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bandarban_2025 = pd.read_csv('../../2025-dataset/bandarban_historical_weather_2025.csv')\n",
    "# df_bandarban_2025 = df_bandarban.drop('district', axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b7822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>temperature(degree C)</th>\n",
       "      <th>feels_like(degree C)</th>\n",
       "      <th>max_temperature(degree C)</th>\n",
       "      <th>minimum_temperature(degree C)</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>atmospheric_pressure</th>\n",
       "      <th>UV</th>\n",
       "      <th>solar_radiation</th>\n",
       "      <th>dew_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandarban</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>25.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1013.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>194.4</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bandarban</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>193.8</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bandarban</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1014.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>172.7</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bandarban</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>172.9</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bandarban</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>15.4</td>\n",
       "      <td>83.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>169.1</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    district  day  month  year  temperature(degree C)  feels_like(degree C)  \\\n",
       "0  Bandarban    1      1  2025                   19.3                  19.3   \n",
       "1  Bandarban    2      1  2025                   18.6                  18.6   \n",
       "2  Bandarban    3      1  2025                   18.3                  18.3   \n",
       "3  Bandarban    4      1  2025                   18.8                  18.8   \n",
       "4  Bandarban    5      1  2025                   20.7                  20.9   \n",
       "\n",
       "   max_temperature(degree C)  minimum_temperature(degree C)  humidity  \\\n",
       "0                       25.8                           14.7      82.9   \n",
       "1                       23.3                           15.8      86.5   \n",
       "2                       22.6                           15.3      90.9   \n",
       "3                       23.4                           15.0      88.9   \n",
       "4                       27.5                           15.4      83.4   \n",
       "\n",
       "   precipitation  windspeed  atmospheric_pressure   UV  solar_radiation  \\\n",
       "0            0.0       18.4                1013.6  7.0            194.4   \n",
       "1            0.0       16.6                1014.1  7.0            193.8   \n",
       "2            0.0       12.1                1014.8  7.0            172.7   \n",
       "3            0.0       11.2                1013.7  7.0            172.9   \n",
       "4            0.0       18.4                1014.6  7.0            169.1   \n",
       "\n",
       "   dew_point  \n",
       "0       16.2  \n",
       "1       16.1  \n",
       "2       16.7  \n",
       "3       16.9  \n",
       "4       17.4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bandarban_2025.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288f774",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
