{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f24f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madaripur = pd.read_csv('../1980-2024-dataset/Madaripur_historical_weather_1980_2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb870570",
   "metadata": {},
   "source": [
    "# For Humidex (Humidity Index)\n",
    "here we are taking temperature and humidity so that data doesn't leak while training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madaripur.info()\n",
    "df_madaripur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madaripur.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a9cc6",
   "metadata": {},
   "source": [
    "# Features for Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73febfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_colmn = ['day', 'month', 'year', 'temperature(degree C)', 'dew_point']\n",
    "HI_df_madaripur = df_madaripur[desired_colmn]\n",
    "\n",
    "HI_df_madaripur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_no_null_HI = HI_df_madaripur.dropna()\n",
    "print(f\"After removing missing values from madaripur, dataset contains {with_no_null_HI.shape[0]} rows and {with_no_null_HI.shape[1]} columns out of {df_madaripur.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd82818",
   "metadata": {},
   "source": [
    "# count zeroes and drop it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49356c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zeros_per_col = (with_no_null_HI == 0).sum()\n",
    "zeros_df = zeros_per_col.to_frame(name='zero_count')\n",
    "zeros_df['zero_percentage'] = (zeros_df['zero_count'] / len(with_no_null_HI) * 100).round(2)\n",
    "zeros_df = zeros_df[zeros_df['zero_count'] > 0].sort_values('zero_count', ascending=False)\n",
    "\n",
    "print(\"Number of zeros per column (only columns with >0 zeros shown):\")\n",
    "display(zeros_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb496f",
   "metadata": {},
   "source": [
    "# time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ensure a datetime column exists\n",
    "if 'date' not in with_no_null_HI.columns:\n",
    "    with_no_null_HI['date'] = pd.to_datetime(with_no_null_HI[['year', 'month', 'day']])\n",
    "\n",
    "# show date range\n",
    "min_date = with_no_null_HI['date'].min()\n",
    "max_date = with_no_null_HI['date'].max()\n",
    "print(f\"Date range: {min_date.date()} to {max_date.date()}\")\n",
    "\n",
    "# plot daily temperature time series\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(with_no_null_HI['date'], with_no_null_HI['temperature(degree C)'], linewidth=0.2)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Daily Temperature ')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot dew point time series\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(with_no_null_HI['date'], with_no_null_HI['dew_point'], linewidth=0.2)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Dew Point')\n",
    "plt.title('Daily Dew Point')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ff3b4",
   "metadata": {},
   "source": [
    "# Random Forest for tem and dewpoint using Fourier series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Start from your *clean* dataframe\n",
    "# ------------------------------------------------------------------\n",
    "# copy and ensure a proper datetime column exists\n",
    "df = with_no_null_HI.copy()\n",
    "if 'date' not in df.columns:\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "\n",
    "temp_col = 'temperature(degree C)'\n",
    "dew_col = 'dew_point'\n",
    "desired_columns = ['day', 'month', 'year', dew_col, temp_col]\n",
    "missing = [c for c in desired_columns if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {missing}. Available columns: {list(df.columns)}\")\n",
    "\n",
    "df = df[desired_columns].copy()\n",
    "\n",
    "\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "def add_fourier_features(df, col, period, n_terms=3):\n",
    "    for n in range(1, n_terms + 1):\n",
    "        df[f'{col}_sin_{n}'] = np.sin(2 * np.pi * n * df[col] / period)\n",
    "        df[f'{col}_cos_{n}'] = np.cos(2 * np.pi * n * df[col] / period)\n",
    "    return df\n",
    "\n",
    "df = add_fourier_features(df, 'day_of_year', period=365.25, n_terms=3)\n",
    "\n",
    "# Collect Fourier columns robustly\n",
    "fourier_cols = [c for c in df.columns if c.startswith('day_of_year_sin') or c.startswith('day_of_year_cos')]\n",
    "\n",
    "\n",
    "FEATURES = ['day', 'month', 'year'] + fourier_cols\n",
    "TARGET = [temp_col, dew_col]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "rf_r2_f  = r2_score(y_test, y_pred)\n",
    "rf_mse_f = mean_squared_error(y_test, y_pred)\n",
    "rf_rmse_f = np.sqrt(rf_mse_f)\n",
    "\n",
    "def tolerance_accuracy(y_true, y_hat, tol):\n",
    "    \"\"\"Return percentage of values within tolerance (works for multi-output).\"\"\"\n",
    "    # y_true/y_hat shape: (n_samples, n_targets)\n",
    "    return 100.0 * (np.abs(y_true - y_hat) <= tol).mean()\n",
    "\n",
    "rf_acc_05 = tolerance_accuracy(y_test.values, y_pred, 0.5)\n",
    "rf_acc_10 = tolerance_accuracy(y_test.values, y_pred, 1.0)\n",
    "rf_acc_20 = tolerance_accuracy(y_test.values, y_pred, 2.0)\n",
    "rf_acc_30 = tolerance_accuracy(y_test.values, y_pred, 3.0)\n",
    "\n",
    "print(\"=== Random Forest + Fourier – Dew-Point Prediction (Test) ===\")\n",
    "print(f\"R²          : {rf_r2_f:.4f}\")\n",
    "print(f\"RMSE        : {rf_rmse_f:.3f} °C\")\n",
    "print(f\"MSE         : {rf_mse_f:.4f}\")\n",
    "print(\"Accuracy (± tolerance):\")\n",
    "print(f\"  ±0.5 °C : {rf_acc_05:5.2f}%\")\n",
    "print(f\"  ±1.0 °C : {rf_acc_10:5.2f}%\")\n",
    "print(f\"  ±2.0 °C : {rf_acc_20:5.2f}%\")\n",
    "print(f\"  ±3.0 °C : {rf_acc_30:5.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 9. 5-fold CV (R²)\n",
    "# ------------------------------------------------------------------\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_cv_r2 = cross_val_score(rf, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(\"\\n=== 5-Fold CV R² (with Fourier) ===\")\n",
    "print(f\"Mean : {rf_cv_r2.mean():.4f}  (±{rf_cv_r2.std():.4f})\")\n",
    "print(f\"Scores: {np.round(rf_cv_r2, 4)}\")\n",
    "\n",
    "fi = pd.DataFrame({\n",
    "    'feature'   : FEATURES,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importances (Top 10) ===\")\n",
    "print(fi.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8d7d1",
   "metadata": {},
   "source": [
    "# XGBoost for tem and dewpoint using Fourier Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# --- 1) Input validation & date ---\n",
    "if 'with_no_null_HI' not in globals() and 'with_no_null_HI' not in locals():\n",
    "    raise NameError(\"Expected DataFrame named `with_no_null_HI` in the environment\")\n",
    "\n",
    "df = with_no_null_HI.copy()\n",
    "if 'date' not in df.columns:\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# --- 2) Required columns & Fourier features ---\n",
    "temp_col = 'temperature(degree C)'\n",
    "dew_col = 'dew_point'\n",
    "required = ['day', 'month', 'year', dew_col, temp_col]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {missing}. Available columns: {list(df.columns)}\")\n",
    "\n",
    "df = df[required].copy()\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "def add_fourier_features(df, col, period=365*3, n_terms=3):\n",
    "    for n in range(1, n_terms+1):\n",
    "        df[f'{col}_sin_{n}'] = np.sin(2 * np.pi * n * df[col] / period)\n",
    "        df[f'{col}_cos_{n}'] = np.cos(2 * np.pi * n * df[col] / period)\n",
    "    return df\n",
    "\n",
    "df = add_fourier_features(df, 'day_of_year', period=365*3, n_terms=3)\n",
    "fourier_cols = [c for c in df.columns if c.startswith('day_of_year_sin') or c.startswith('day_of_year_cos')]\n",
    "\n",
    "# --- 3) Features and targets ---\n",
    "FEATURES = ['day', 'month', 'year'] + fourier_cols\n",
    "TARGET = [temp_col, dew_col]\n",
    "\n",
    "X = df[FEATURES].astype(float)\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# --- 4) Train MultiOutput XGBoost ---\n",
    "base_xgb = xgb.XGBRegressor( \n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "model = MultiOutputRegressor(base_xgb)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 5) Predictions & metrics ---\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "xgboost_r2_f  = r2_score(y_test, y_pred)            # averaged R^2 for multioutput\n",
    "xgboost_mse_f = mean_squared_error(y_test, y_pred)  # averaged MSE\n",
    "xgboost_rmse_f = np.sqrt(xgboost_mse_f)\n",
    "\n",
    "def within_tolerance_acc(y_true, y_hat, tol):\n",
    "    # returns fraction (0..1) of predictions within tol across all targets\n",
    "    return ((np.abs(y_true - y_hat) <= tol).mean())\n",
    "\n",
    "xgboost_acc_05 = within_tolerance_acc(y_test.values, y_pred, 0.5)\n",
    "xgboost_acc_10 = within_tolerance_acc(y_test.values, y_pred, 1.0)\n",
    "xgboost_acc_20 = within_tolerance_acc(y_test.values, y_pred, 2.0)\n",
    "xgboost_acc_30 = within_tolerance_acc(y_test.values, y_pred, 3.0)\n",
    "\n",
    "print(\"==== XGBoost Regression Metrics (Test) ====\")\n",
    "print(f\"xgboost_R^2  : {xgboost_r2_f:.4f}\")\n",
    "print(f\"xgboost_MSE  : {xgboost_mse_f:.4f}\")\n",
    "print(f\"xgboost_RMSE : {xgboost_rmse_f:.4f}\")\n",
    "print(\"Accuracy (|error| ≤ tolerance):\")\n",
    "print(f\"  ±0.5°C : {xgboost_acc_05*100:.2f}%\")\n",
    "print(f\"  ±1.0°C : {xgboost_acc_10*100:.2f}%\")\n",
    "print(f\"  ±2.0°C : {xgboost_acc_20*100:.2f}%\")\n",
    "print(f\"  ±3.0°C : {xgboost_acc_30*100:.2f}%\")\n",
    "\n",
    "# --- 6) 5-fold CV R^2 ---\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=cv, scoring=\"r2\", n_jobs=-1)\n",
    "print(\"\\n==== 5-Fold CV R^2 ====\")\n",
    "print(f\"Mean xgboost_R^2 : {cv_r2.mean():.4f}  |  Std : {cv_r2.std():.4f}\")\n",
    "\n",
    "# --- 7) Feature importances (average across outputs) ---\n",
    "# MultiOutputRegressor stores estimators_ after fit\n",
    "importances = np.array([est.feature_importances_ for est in model.estimators_])\n",
    "mean_importance = importances.mean(axis=0)\n",
    "fi = pd.DataFrame({\"feature\": FEATURES, \"importance\": mean_importance}).sort_values(\"importance\", ascending=False)\n",
    "print(\"\\n==== Top Feature Importances ====\")\n",
    "print(fi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2593b",
   "metadata": {},
   "source": [
    "# LightGBM + fourier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# --- 1) Input validation & date ---\n",
    "if 'with_no_null_HI' not in globals() and 'with_no_null_HI' not in locals():\n",
    "    raise NameError(\"Expected DataFrame named `with_no_null_HI` in the environment\")\n",
    "\n",
    "df = with_no_null_HI.copy()\n",
    "if 'date' not in df.columns:\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# --- 2) Required columns & Fourier features ---\n",
    "temp_col = 'temperature(degree C)'\n",
    "dew_col = 'dew_point'\n",
    "required = ['day', 'month', 'year', dew_col, temp_col]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {missing}. Available columns: {list(df.columns)}\")\n",
    "\n",
    "df = df[required].copy()\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Fourier feature function\n",
    "def add_fourier_features(df, col, period=365*3, n_terms=3):\n",
    "    for n in range(1, n_terms+1):\n",
    "        df[f'{col}_sin_{n}'] = np.sin(2 * np.pi * n * df[col] / period)\n",
    "        df[f'{col}_cos_{n}'] = np.cos(2 * np.pi * n * df[col] / period)\n",
    "    return df\n",
    "\n",
    "df = add_fourier_features(df, 'day_of_year', period=365*3, n_terms=3)\n",
    "fourier_cols = [c for c in df.columns if c.startswith('day_of_year_sin') or c.startswith('day_of_year_cos')]\n",
    "\n",
    "# --- 3) Features and targets ---\n",
    "FEATURES = ['day', 'month', 'year'] + fourier_cols\n",
    "TARGET = [temp_col, dew_col]\n",
    "\n",
    "X = df[FEATURES].astype(float)\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "# --- 4) Train MultiOutput LightGBM ---\n",
    "base_lgb = lgb.LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = MultiOutputRegressor(base_lgb)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- 5) Predictions & metrics ---\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "lgb_r2_f  = r2_score(y_test, y_pred)\n",
    "lgb_mse_f = mean_squared_error(y_test, y_pred)\n",
    "lgb_rmse_f = np.sqrt(lgb_mse_f)\n",
    "\n",
    "def within_tolerance_acc(y_true, y_hat, tol):\n",
    "    return ((np.abs(y_true - y_hat) <= tol).mean())\n",
    "\n",
    "lgb_acc_05 = within_tolerance_acc(y_test.values, y_pred, 0.5)\n",
    "lgb_acc_10 = within_tolerance_acc(y_test.values, y_pred, 1.0)\n",
    "lgb_acc_20 = within_tolerance_acc(y_test.values, y_pred, 2.0)\n",
    "lgb_acc_30 = within_tolerance_acc(y_test.values, y_pred, 3.0)\n",
    "\n",
    "print(\"==== LightGBM Regression Metrics (Test) ====\")\n",
    "print(f\"LGB_R^2  : {lgb_r2_f:.4f}\")\n",
    "print(f\"LGB_MSE  : {lgb_mse_f:.4f}\")\n",
    "print(f\"LGB_RMSE : {lgb_rmse_f:.4f}\")\n",
    "print(\"Accuracy (|error| ≤ tolerance):\")\n",
    "print(f\"  ±0.5°C : {lgb_acc_05*100:.2f}%\")\n",
    "print(f\"  ±1.0°C : {lgb_acc_10*100:.2f}%\")\n",
    "print(f\"  ±2.0°C : {lgb_acc_20*100:.2f}%\")\n",
    "print(f\"  ±3.0°C : {lgb_acc_30*100:.2f}%\")\n",
    "\n",
    "# --- 6) 5-fold CV R^2 ---\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=cv, scoring=\"r2\", n_jobs=-1)\n",
    "\n",
    "print(\"\\n==== 5-Fold CV R^2 ====\")\n",
    "print(f\"Mean LGB_R^2 : {cv_r2.mean():.4f}  |  Std : {cv_r2.std():.4f}\")\n",
    "\n",
    "# --- 7) Feature importances (average across outputs) ---\n",
    "importances = np.array([est.feature_importances_ for est in model.estimators_])\n",
    "mean_importance = importances.mean(axis=0)\n",
    "fi = pd.DataFrame({\"feature\": FEATURES, \"importance\": mean_importance}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n==== Top Feature Importances ====\")\n",
    "print(fi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412e29e",
   "metadata": {},
   "source": [
    "# show the comparision of all the models in a table. fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the comparision of all the models in a table.based on R^2, MSE, RMSE, and accuracy within tolerances.\n",
    "# Summary of model performance\n",
    "model_performance = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"XGBoost\", \"LightGBM\"],\n",
    "    \"R^2\": [rf_r2_f, xgboost_r2_f, lgb_r2_f],  # Replace with actual R^2 values from each model\n",
    "    \"MSE\": [rf_mse_f, xgboost_mse_f, lgb_mse_f],  # Replace with actual MSE values from each model\n",
    "    \"RMSE\": [rf_rmse_f, xgboost_rmse_f, lgb_rmse_f],  # Replace with actual RMSE values from each model\n",
    "    \"Acc ±0.5°C (%)\": [rf_acc_05*100, xgboost_acc_05*100, lgb_acc_05*100],  # Replace with actual accuracy values\n",
    "    \"Acc ±1.0°C (%)\": [rf_acc_10*100, xgboost_acc_10*100, lgb_acc_10*100],\n",
    "    \"Acc ±2.0°C (%)\": [rf_acc_20*100, xgboost_acc_20*100, lgb_acc_20*100],\n",
    "    \"Acc ±3.0°C (%)\": [rf_acc_30*100, xgboost_acc_30*100, lgb_acc_30*100],\n",
    "})\n",
    "print(\"\\n==== Model Performance Comparison ====\")\n",
    "print(model_performance.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec3b10",
   "metadata": {},
   "source": [
    "# Selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(df, sort_by_metrics):\n",
    "    \"\"\"\n",
    "    Ranks models based on a list of metrics (in order of priority) \n",
    "    and returns the best model name.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The model performance DataFrame.\n",
    "        sort_by_metrics (list of tuples): A list where each tuple is \n",
    "            (metric_name, maximize_boolean). \n",
    "            True=Higher is better (e.g., R^2, Accuracy).\n",
    "            False=Lower is better (e.g., MSE, RMSE).\n",
    "    \n",
    "    Returns:\n",
    "        str: The name of the best performing model.\n",
    "    \"\"\"\n",
    "    \n",
    "    sort_cols = [metric[0] for metric in sort_by_metrics]\n",
    "    # If maximize=True, we use ascending=False (for descending order).\n",
    "    # If maximize=False, we use ascending=True (for ascending order).\n",
    "    ascending_list = [not metric[1] for metric in sort_by_metrics]\n",
    "\n",
    "    # Rank the models using multiple columns for tie-breaking\n",
    "    ranked_df = df.sort_values(\n",
    "        by=sort_cols, \n",
    "        ascending=ascending_list\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    best_model_name = ranked_df.iloc[0]['Model']\n",
    "    \n",
    "    print(\"\\n--- Model Ranking Based on Current Strategy ---\")\n",
    "    # Show only the Model column and the metrics used for ranking\n",
    "    print(ranked_df[['Model'] + sort_cols].to_string(index=False))\n",
    "    \n",
    "    return best_model_name\n",
    "\n",
    "\n",
    "MODEL_NAMES = [\"Random Forest\", \"XGBoost\", \"LightGBM\"]\n",
    "R_SQUARED_VALUES = [rf_r2_f, xgboost_r2_f, lgb_r2_f]\n",
    "MSE_VALUES = [rf_mse_f, xgboost_mse_f, lgb_mse_f]\n",
    "RMSE_VALUES = [rf_rmse_f, xgboost_rmse_f, lgb_rmse_f]\n",
    "ACC_0_5_VALUES = [rf_acc_05*100, xgboost_acc_05*100, lgb_acc_05*100]\n",
    "ACC_1_0_VALUES = [rf_acc_10*100, xgboost_acc_10*100, lgb_acc_10*100]\n",
    "ACC_2_0_VALUES = [rf_acc_20*100, xgboost_acc_20*100, lgb_acc_20*100]\n",
    "ACC_3_0_VALUES = [rf_acc_30*100, xgboost_acc_30*100, lgb_acc_30*100]\n",
    "\n",
    "\n",
    "# You can add more metric value lists here if needed!\n",
    "\n",
    "# B. Construct the DataFrame using the variables above\n",
    "#    The dictionary keys become your column names (e.g., 'RMSE', 'Acc ±0.5 (%)').\n",
    "data = {\n",
    "    \"Model\": MODEL_NAMES,\n",
    "    \"R^2\": R_SQUARED_VALUES,\n",
    "    \"MSE\": MSE_VALUES,\n",
    "    \"RMSE\": RMSE_VALUES,\n",
    "    \"Acc ±0.5 (%)\": ACC_0_5_VALUES,\n",
    "    \"Acc ±1.0 (%)\": ACC_1_0_VALUES,\n",
    "    \"Acc ±2.0 (%)\": ACC_2_0_VALUES,\n",
    "    \"Acc ±3.0 (%)\": ACC_3_0_VALUES,\n",
    "}\n",
    "\n",
    "df_performance = pd.DataFrame(data)\n",
    "\n",
    "# =======================================================================\n",
    "# 3. STRATEGY DEFINITION: EDIT THESE LISTS TO DEFINE YOUR PRIORITIES\n",
    "# =======================================================================\n",
    "\n",
    "# Define Strategy 1: Prioritizing low error (RMSE) first, then high R^2\n",
    "# Structure: [('Metric Name', Is_Maximize)]\n",
    "strategy_1_metrics = [\n",
    "    (\"RMSE\", False),   # False = Minimize (Lower is better)\n",
    "    (\"R^2\", True)      # True = Maximize (Higher is better)\n",
    "]\n",
    "\n",
    "# Define Strategy 2: Prioritizing tight accuracy (Acc ±0.5 %), then low MSE\n",
    "strategy_2_metrics = [\n",
    "    (\"Acc ±0.5 (%)\", True), # True = Maximize\n",
    "    (\"MSE\", False)          # False = Minimize (as a tiebreaker)\n",
    "]\n",
    "\n",
    "strategy_3_0_metrics = [\n",
    "    (\"Acc ±1.0 (%)\", True), # True = Maximize\n",
    "    (\"MSE\", False)          # False = Minimize (as a tiebreaker)\n",
    "]\n",
    "\n",
    "# =======================================================================\n",
    "# 4. EXECUTION\n",
    "# =======================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"             MODEL PERFORMANCE TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_performance.to_string(index=False))\n",
    "\n",
    "# --- Run Strategy 1 ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1: Prioritizing RMSE (Minimize) -> R^2 (Maximize)\")\n",
    "print(\"=\"*60)\n",
    "best_model_1 = select_best_model(df_performance, strategy_1_metrics)\n",
    "print(f\"\\n✅ BEST MODEL FOR STRATEGY 1: {best_model_1}\")\n",
    "\n",
    "\n",
    "# --- Run Strategy 2 ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2: Prioritizing Acc ±0.5 % (Maximize) -> MSE (Minimize)\")\n",
    "print(\"=\"*60)\n",
    "best_model_2 = select_best_model(df_performance, strategy_2_metrics)\n",
    "print(f\"\\n✅ BEST MODEL FOR STRATEGY 2: {best_model_2}\")\n",
    "\n",
    "# --- Run Strategy 3 ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3: Prioritizing Acc ±1.0 % (Maximize) -> MSE (Minimize)\")\n",
    "print(\"=\"*60)\n",
    "best_model_3 = select_best_model(df_performance, strategy_3_0_metrics)\n",
    "print(f\"\\n✅ BEST MODEL FOR STRATEGY 3: {best_model_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340c3a3",
   "metadata": {},
   "source": [
    "# predicting next 3 years using the best model:\n",
    "- here random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f2b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = with_no_null_HI.copy()\n",
    "TARGET = ['temperature(degree C)', 'dew_point']\n",
    "temp_col, dew_col = TARGET\n",
    "\n",
    "# Ensure date exists\n",
    "if \"date\" not in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\",\"month\",\"day\"]])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# ============================================================\n",
    "# 1) Create next 365 calendar dates\n",
    "# ============================================================\n",
    "last_date = df[\"date\"].max()\n",
    "future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=365*3, freq=\"D\")\n",
    "\n",
    "future_df = pd.DataFrame({\"date\": future_dates})\n",
    "future_df[\"year\"]  = future_df[\"date\"].dt.year\n",
    "future_df[\"month\"] = future_df[\"date\"].dt.month\n",
    "future_df[\"day\"]   = future_df[\"date\"].dt.day\n",
    "future_df[\"day_of_year\"] = future_df[\"date\"].dt.dayofyear\n",
    "\n",
    "# ============================================================\n",
    "# 2) Add FOURIER FEATURES exactly like training\n",
    "# ============================================================\n",
    "def add_fourier_features(df, col, period=365*3, n_terms=3):\n",
    "    for n in range(1, n_terms + 1):\n",
    "        df[f\"{col}_sin_{n}\"] = np.sin(2 * np.pi * n * df[col] / period)\n",
    "        df[f\"{col}_cos_{n}\"] = np.cos(2 * np.pi * n * df[col] / period)\n",
    "    return df\n",
    "\n",
    "future_df = add_fourier_features(future_df, \"day_of_year\", 365.25, n_terms=3)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Build monthly-day climatology (baseline)\n",
    "# ============================================================\n",
    "hist = df.copy()\n",
    "hist[\"month\"] = hist[\"date\"].dt.month\n",
    "hist[\"day\"]   = hist[\"date\"].dt.day\n",
    "\n",
    "clim = (\n",
    "    hist.groupby([\"month\",\"day\"])[[temp_col, dew_col]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        temp_col: temp_col + \"_clim\",\n",
    "        dew_col:  dew_col  + \"_clim\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# Merge with future calendar\n",
    "future_with_clim = future_df.merge(clim, on=[\"month\",\"day\"], how=\"left\")\n",
    "\n",
    "# Fallback to last 7-day mean if climatology missing\n",
    "recent_temp = hist[temp_col].tail(7).mean()\n",
    "recent_dew  = hist[dew_col].tail(7).mean()\n",
    "\n",
    "future_with_clim[temp_col] = future_with_clim[temp_col + \"_clim\"].fillna(recent_temp)\n",
    "future_with_clim[dew_col]  = future_with_clim[dew_col  + \"_clim\"].fillna(recent_dew)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Build X_future EXACTLY as the RF was trained\n",
    "# ============================================================\n",
    "FEATURES = list(rf.feature_names_in_)   # <---- CRITICAL FIX\n",
    "\n",
    "missing = [f for f in FEATURES if f not in future_with_clim.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing Fourier features in future data: {missing}\")\n",
    "\n",
    "X_future = future_with_clim[FEATURES].copy()\n",
    "\n",
    "# ============================================================\n",
    "# 5) Predict with trained RF model\n",
    "# ============================================================\n",
    "future_pred = rf.predict(X_future)\n",
    "\n",
    "# ============================================================\n",
    "# 6) Output DataFrame (same format as your template)\n",
    "# ============================================================\n",
    "rf_forecast_out2 = future_with_clim[[\"date\", \"year\", \"month\", \"day\"]].copy()\n",
    "\n",
    "# Split two-target RF predictions\n",
    "rf_forecast_out2[\"pred_\" + temp_col] = future_pred[:, 0]\n",
    "rf_forecast_out2[\"pred_\" + dew_col]  = future_pred[:, 1]\n",
    "\n",
    "# Add climatology (baseline) values\n",
    "rf_forecast_out2[temp_col] = future_with_clim[temp_col]\n",
    "rf_forecast_out2[dew_col]  = future_with_clim[dew_col]\n",
    "\n",
    "print(\"==== 365-step Forecast Using Fourier + Random Forest ====\")\n",
    "print(rf_forecast_out2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a9ca8",
   "metadata": {},
   "source": [
    "<h1>Calculating Humidity Index using raw data(1980-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ecf909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp_col = 'temperature(degree C)'\n",
    "dew_col = 'dew_point'\n",
    "\n",
    "def calculate_humidex(T_c, D_c):\n",
    "    \"\"\"\n",
    "    Humidex = T + 0.5555 × (6.11 × exp(5417.7530 × (1/273.16 - 1/(273.15 + D))) - 10)\n",
    "    T_c : temperature in °C\n",
    "    D_c : dew point in °C\n",
    "    Returns humidex in °C (float) or np.nan if inputs invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(T_c) or pd.isna(D_c):\n",
    "            return np.nan\n",
    "        T = float(T_c)\n",
    "        D = float(D_c)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "    # Avoid -inf/overflow but the formula is stable for realistic D values.\n",
    "    exponent = 5417.7530 * (1.0/273.16 - 1.0/(273.15 + D))\n",
    "    e_term = 6.11 * np.exp(exponent)\n",
    "    humidex = T + 0.5555 * (e_term - 10.0)\n",
    "    return humidex\n",
    "\n",
    "# Apply to dataframe (vectorized via .apply is fine here)\n",
    "with_no_null_HI['humidity_index'] = with_no_null_HI.apply(\n",
    "    lambda r: calculate_humidex(r[temp_col], r[dew_col]), axis=1)\n",
    "\n",
    "# Quick checks (keeps your existing calls)\n",
    "with_no_null_HI['humidity_index'].info()\n",
    "with_no_null_HI.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18673aca",
   "metadata": {},
   "source": [
    "- <30 = Comfortable;\n",
    "- 30-40 = Some discomfort;\n",
    "- 40-45 = Great discomfort (avoid exertion);\n",
    "- >45 = Dangerous (heatstroke possible). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f06635b",
   "metadata": {},
   "source": [
    "<h1> Calculating humidty index using predicted temperature and dew point Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp_col = 'pred_temperature(degree C)'\n",
    "dew_col = 'pred_dew_point'\n",
    "\n",
    "def calculate_humidex(T_c, D_c): \n",
    "    \"\"\"\n",
    "    Humidex = T + 0.5555 × (6.11 × exp(5417.7530 × (1/273.16 - 1/(273.15 + D))) - 10)\n",
    "    T_c : temperature in °C\n",
    "    D_c : dew point in °C\n",
    "    Returns humidex in °C (float) or np.nan if inputs invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(T_c) or pd.isna(D_c):\n",
    "            return np.nan\n",
    "        T = float(T_c)\n",
    "        D = float(D_c)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "    exponent = 5417.7530 * (1.0/273.16 - 1.0/(273.15 + D))\n",
    "    e_term = 6.11 * np.exp(exponent)\n",
    "    humidex = T + 0.5555 * (e_term - 10.0)\n",
    "    return humidex\n",
    "\n",
    "# Calculate Humidex first\n",
    "humidex_values = rf_forecast_out2.apply(lambda r: calculate_humidex(r[temp_col], r[dew_col]), axis=1)\n",
    "\n",
    "# Assign the result as a new column\n",
    "rf_forecast_out2 = rf_forecast_out2.copy()  # optional, avoids SettingWithCopyWarning\n",
    "rf_forecast_out2['pred_humidity_index'] = humidex_values\n",
    "\n",
    "# Quick checks\n",
    "rf_forecast_out2['pred_humidity_index'].info()\n",
    "rf_forecast_out2.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca47383f",
   "metadata": {},
   "source": [
    "# 2025 testing data for validation (original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madaripur_2025_validation = pd.read_csv('../2025-dataset/madaripur_historical_weather_2025.csv')\n",
    "desired_column_2025 = ['day', 'month', 'year', 'temperature(degree C)', 'dew_point']\n",
    "HI_df_madaripur_2025 = df_madaripur_2025_validation[desired_column_2025]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of zeros per column (only columns with >0 zeros shown):\")\n",
    "display(zeros_df)\n",
    "no_null_HI_2025 = HI_df_madaripur_2025.dropna()\n",
    "print(f\"After removing missing values from madaripur, dataset contains {no_null_HI_2025.shape[0]} rows and {no_null_HI_2025.shape[1]} columns out of {df_madaripur_2025_validation.shape[0]} rows.\")\n",
    "no_null_HI_2025.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591cfe8",
   "metadata": {},
   "source": [
    "<h1> Calculating humidity index for 2025 raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp_col = 'temperature(degree C)'\n",
    "dew_col = 'dew_point'\n",
    "\n",
    "def calculate_humidex(T_c, D_c):\n",
    "    \"\"\"\n",
    "    Humidex = T + 0.5555 × (6.11 × exp(5417.7530 × (1/273.16 - 1/(273.15 + D))) - 10)\n",
    "    T_c : temperature in °C\n",
    "    D_c : dew point in °C\n",
    "    Returns humidex in °C (float) or np.nan if inputs invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(T_c) or pd.isna(D_c):\n",
    "            return np.nan\n",
    "        T = float(T_c)\n",
    "        D = float(D_c)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "    # Avoid -inf/overflow but the formula is stable for realistic D values.\n",
    "    exponent = 5417.7530 * (1.0/273.16 - 1.0/(273.15 + D))\n",
    "    e_term = 6.11 * np.exp(exponent)\n",
    "    humidex = T + 0.5555 * (e_term - 10.0)\n",
    "    return humidex\n",
    "\n",
    "# Apply to dataframe (vectorized via .apply is fine here)\n",
    "no_null_HI_2025['humidity_index'] = no_null_HI_2025.apply(\n",
    "    lambda r: calculate_humidex(r[temp_col], r[dew_col]), axis=1)\n",
    "\n",
    "# Quick checks (keeps your existing calls)\n",
    "no_null_HI_2025['humidity_index'].info()\n",
    "no_null_HI_2025.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fc42f",
   "metadata": {},
   "source": [
    "<h1>Plotting raw vs 2025-2027 predicted value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "def ensure_date(df):\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "    return df\n",
    "\n",
    "no_null_HI_2025 = ensure_date(no_null_HI_2025)\n",
    "rf_forecast_out2 = ensure_date(rf_forecast_out2)\n",
    "\n",
    "no_null_HI_2025 = no_null_HI_2025.set_index(\"date\")\n",
    "rf_forecast_out2 = rf_forecast_out2.set_index(\"date\")\n",
    "\n",
    "plt.plot(no_null_HI_2025.index, no_null_HI_2025['humidity_index'], \n",
    "         label='Actual Humidity Index of 2025', color='magenta')\n",
    "\n",
    "plt.plot(rf_forecast_out2.index, rf_forecast_out2['pred_humidity_index'], \n",
    "         label='Predicted Heat Index 2025-2027 (°C)', color='blue')\n",
    "\n",
    "plt.xlabel('Timeline (2025 - 2027)')\n",
    "plt.ylabel('Humidity Index (°C)')\n",
    "plt.title(' Madaripur Actual vs Predicted Humidity Index for 2025-2027')\n",
    "\n",
    "bands = [\n",
    "    (10, 30, \"Comfortable (<30°C)\", (0, 1, 0, 0.07)),\n",
    "    (30, 40, \"Some discomfort (30–40°C)\", (1, 1, 0, 0.07)),\n",
    "    (40, 45, \"Great discomfort (40–45°C)\", (1, 0.5, 0, 0.07)),\n",
    "    (45, 60, \"Danger (>45°C)\", (1, 0, 0, 0.07))\n",
    "]\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for low, high, label, color in bands:\n",
    "    ax.axhspan(low, high, facecolor=color, edgecolor=None)\n",
    "    plt.axhline(y=low, color='red', linestyle='--', linewidth=0.8)\n",
    "    plt.axhline(y=high, color='red', linestyle='--', linewidth=0.8)\n",
    "    plt.text(\n",
    "        x=no_null_HI_2025.index.min(),\n",
    "        y=(low + high) / 2,\n",
    "        s=label,\n",
    "        fontsize=11,\n",
    "        color=\"maroon\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4235b37",
   "metadata": {},
   "source": [
    "# number of days count depending on the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 to 40 degrees celsius (some discomfort)\n",
    "days_30_40 = rf_forecast_out2[\n",
    "    (rf_forecast_out2['pred_humidity_index'] >= 30) & \n",
    "    (rf_forecast_out2['pred_humidity_index'] < 40)\n",
    "].shape[0]\n",
    "print(f\"Number of days with predicted Humidity Index between 30°C and 40°C: {days_30_40} days\")\n",
    "# 40 to 45 degrees celsius (great discomfort )\n",
    "days_40_45 = rf_forecast_out2[\n",
    "    (rf_forecast_out2['pred_humidity_index'] >= 40) & \n",
    "    (rf_forecast_out2['pred_humidity_index'] < 45)\n",
    "].shape[0]\n",
    "print(f\"Number of days with predicted Humidity Index between 40°C and 45°C: {days_40_45} days\")\n",
    "# above 45 degrees celsius ( danger )\n",
    "days_above_45 = rf_forecast_out2[\n",
    "    (rf_forecast_out2['pred_humidity_index'] >= 45)\n",
    "].shape[0]\n",
    "print(f\"Number of days with predicted Humidity Index above 45°C: {days_above_45} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e496b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
